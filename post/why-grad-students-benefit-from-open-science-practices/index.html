<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author"      content="Sergey Pozhilov (GetTemplate.com)">

	<title>Why grad students benefit from open science practices</title>

	<link rel="shortcut icon" href="https://rxqx.github.ioimages/tattoocrop.jpeg">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic|Quicksand:500">
	
	<link rel="stylesheet" href="https://rxqx.github.io/css/styles.css">

	

    
        <script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=&product=inline-share-buttons"></script>
    

</head>
<body class="home">

<header id="header">
	<div id="head">
		<h1 id="logo" class="text-center">
			<span class="title">Rita M. Ludwig, M.A., M.S.</span>
		</h1>
	</div>

    <nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
                
                <li>
                    <a href="../../">home</a>
                </li>
                
                <li>
                    <a href="../../about/">cv</a>
                </li>
                
                <li>
                    <a href="../../research/">research</a>
                </li>
                
                <li>
                    <a href="../../post/">blog</a>
                </li>
                
                <li>
                    <a href="../../about/"></a>
                </li>
                
                
            </ul>

        </div>
    </div>
</nav>


</header>
</body>
</html>


<main id="main">

	<div class="container">

		<div class="row topspace">
			<div class="col-sm-14">

 				<article class="post">
 				  <header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-03-14 00:00:00 &#43;0000 UTC">March 14, 2019</time></span>
						</div>
 				  <h2 class="section-title">Why grad students benefit from open science practices</a></h2>
					<div class="entry-content">
						<p style="text-align:center;"><img src="opensciencebadges.png" alt="Open science badges">
<br> Open science badges created and maintained by the <a href="https://osf.io/tvyxz/wiki/home/"target="null">Open Science Collaboration</a></p>

<h2 class="section-title"><span>The Context</span></h2>

<p>We are in the midst of a paradigm shift in psychology. It has been less than ten years since the <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797611417632" target="null">Simmons, Nelson, and Simonsohn &ldquo;False-Positive Psychology&rdquo; paper</a> demonstrated &ldquo;how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis,&rdquo; calling into question the legitimacy of standard research proceedures used in many psychology labs. A month later, the Open Science Framework lead a team of 270 psychologists in a massive endeavor to reproduce 100 findings published in top psychology journals. In 2015, the results of this <a href="https://osf.io/ezcuj/wiki/home/" target="null">&lsquo;Reproducibility Project&rsquo;</a> revealed that only 39% of the original reported effects were reproduced, leading many to conclude that psychology had entered a replication crisis. The scientific integrity of the field&rsquo;s research was being called into question by those both within and outside it, as <a href="http://www.slate.com/articles/health_and_science/cover_story/2016/03/ego_depletion_an_influential_theory_in_psychology_may_have_just_been_debunked.html" target="null">one</a> <a href="https://www.newsweek.com/power-poses-dont-make-you-more-powerful-studies-664261" target="null">by</a> <a href="https://digest.bps.org.uk/2016/09/01/no-reason-to-smile-another-modern-psychology-classic-has-failed-to-replicate/" target="null">one</a> famous effects fell like dominoes.</p>

<p>The sudden thrust of the field under the scrutiny of many <a href="http://datacolada.org/wp-content/uploads/2015/05/Small-Telescopes-Published.pdf" target="null">&lsquo;small telescopes&rsquo;</a> led to a valiant, collective attempt at course correction. New tools such as <a href="http://www.p-curve.com/" target="null">pcurve</a> and <a href="http://statcheck.io/" target="null">statcheck</a> made it easier to detect whether reported statistics were incorrect or improbable, in published studies or one&rsquo;s own work. 2016 saw the first meeting of the <a href="http://improvingpsych.org/" target="null">Society for the Improvement of Psychological Science</a>, catalyzing collaborative projects aimed at strengthening the evidenciary value of our research such as <a href="https://journals.sagepub.com/doi/10.1177/1745691617708630" target="null">constraints on generality</a> and <a href="https://osf.io/view/studyswap/" target="null">StudySwap</a>. Journals increasingly started to employ <a href="https://cos.io/our-services/open-science-badges/" target="null">open science badges</a> and <a href="https://cos.io/our-services/top-guidelines/" target="null"> TOP guidelines</a>, and accept <a href="https://cos.io/rr/" target="null">registered reports</a>. Reproducible science had become a movement in its own right within psychology, and its proponents believed that the values of open materials, pre-registration, and multilab collaboration were the keys to ending the crisis. With the emergence of this movement the field seemed to be on the verge of a scientific revolution.</p>

<blockquote style="text-align:center;background-color:black;color:white;font-family:serif;font-size:175%;"><i>"Reproducible science had become a movement, and its proponents believed that the values of open materials, pre-registration, and multilab collaboration were the keys to ending the crisis."</i></blockquote>

<h2 class="section-title"><span>The Concerns</span></h2>

<p>During any paradigm shift the group that has the most at risk are those with the least power, who have no choice but hold on tight and try to ride out the clashes between new and old high-status figures. Part of the reason for this post is to honestly discuss some of the potential consequences of psychology&rsquo;s shift from the perspective of a low-power position within the academic hierarchy: that of a graduate student. Grad student education and professional development are inherently dependent upon one&rsquo;s home department and faculty advisor, and access to prestige-building opportunities such as publications, awards, and speaking invitations are additionally dependent on the standards and interests of the field. Thus, a graduate student&rsquo;s future life outcomes, especially their potential employment prospects, are shaped by a diverse assortment of gatekeepers who pass on their own standards for scientific excellence. With the ongoing conflict between traditional and open science schools of psychology, current graduate students are seeing the definition of what it means to be an employable psychologist shift under their feet. Where to land on either side of the dividing line between these two schools of thought can therefore be a risky decision for current graduate students preparing for the job market while the field itself is unsettled.</p>

<p>The concerns that I have heard both first- and second-hand from other graduate students indeed indicate that evaluating this risk may lead to reluctance to adopt open science practices in their own work. The prevailing wisdom is that to be competitive for academic jobs one should maximize first-author publications and publications in high-impact journals, and some grads worry that open science methods are (currently) practically at odds with these goals. It is true that for some areas, switching from a traditional psychology research framework to one focused on openness and reproducibility can slow the progression of research question to published manuscript down. Pre-registration, testing replicability of effects, and making data and materials open all take time. It may therefore seem risky to not instead spend this time pursuing status quo publication, especially if your peers (and potential fellow job applicants) are not expending the time on these efforts themselves. Similarly, the time and effort spent conducting a replication study or contributing to a many labs initiative is comparable to that of individual, novel projects, but may appear less prestigious to some journals or hiring committees (especially if one is not fist author). When time, funding, and other resources are scarce and one&rsquo;s future is on the line, it may therefore seem less risky to maintain the status quo - and this perceived risk only looms larger for students who are working in traditional psychology labs or under advisors reluctant (or opposed) to open science efforts.</p>

<p>But having advanced through grad school simultaneously with the building of the open science movement, and having worked in both traditional and open psychology labs, my message to fellow grads is this: the most valuable use of your limited resources is in practicing open and reproducible science. The benefits of these initiatives include learning an array of marketable skills, shrinking the timeline from project initiation to citable product, and empowering networking and collaboration across areas, fields, and continents. I hope that the following section can convince you that adopting open practices is not a risk, but rather a boon to your professional development.</p>

<blockquote style="text-align:center;background-color:black;color:white;font-family:serif;font-size:175%;"><i>"My message to fellow grads is this: the most valuable use of your limited resources is in practicing open and reproducible science."</i></blockquote>

<h2 class="section-title"><span>The Benefits</span></h2>

<ul style="list-style-type:circle">
  <li><h5>Open science encourages deep thinking.</h5> As academics we are, of course, in the business of thinking. But many of us have had the experience of jumping head first into the deep end of a new research project and later facing unanticipated issues, or making off-the-cuff decisions because a protracted discussion would halt the project's momentum. While these events may seem small and inconsequential for the study's integrity in the moment, they could actually be meaningfully changing how the results should be interpreted. For example, let's say you are halfway through data collection for a study with deception and discover that during debriefing a handful of participants were wise to the manipulation. Now what? Your decision could influence your results by removing data not-at-random (dropping all wise participants from final tests), artifically inflating your p values (conducting a significance test to see if wise participants show the effect, then continuing with data collection if so), or contaminating the controlled part of your experiment (changing the study design mid-collection). And, more concerning, this decision may wind up as a footnote in your methods section rather than a substantial piece of your conclusion given its potential to alter the statistical assumptions behind your significance tests. <br><br>The open science practice of pre-registration offers a buffer against making quick decisions with potential drastic effects by formally incorporating in-depth thinking about study design and statistical analysis into project planning. Pre-registrations are written and frozen on a repository such as the Open Science Framework prior to the collection and analysis of data. This process is beneficial to grad students' statistical thinking by training them to answer the questions of 'how','why', and 'what if' in planning their research. <a href="https://osf.io/zab38/wiki/home/" target="nul">There are a variety of pre-registration templates available for use on the OSF</a>, but they share similar questions such as: <ul style="list-style-type:disc">  
  <li><b>How</b> will you choose your sample size?</li>
  <li><b>How</b> will you operationalize your variables?</li>
  <li><b>Why</b> are your hypotheses directional or not?</li>
  <li><b>Why</b> are you reporting that statistic?</li>
  <li><b>What if</b> your data are heavily skewed?</li>
  <li><b>What if</b> you observe outliers in your data?</li></ul>
Upon completing a pre-registration you will have a 'recipe' for your study that includes (as much as humanly possible) answers to issues that could pop up during the life of the project. You'll also have taken the time to think about and record the justification for your design decisions. And ideally you'll be able to step back and consider how all of the components in this document relate to the interpretion of the results you'll eventually find. Thus, the benefit is in making statistical thinking habitual, planned, and thoughtful, improving not only your skills, but also the veracity of your work.</li><br>
  <li><h5>Open science shortens the timeline from project initiation to citable product.</h5> In contrast to the concernt that I have heard expressed that open science initiatives slow down the publication process, my personal experience is that it can speed things up. There are two open science initiatives that are excellent vehicles for getting your work out of the lab and on your CV. <b>Registered reports</b> are essentially pre-registrations that are sent to journals for peer review. In Phase One of a registered report, authors submit an introduction section as well as sections for planned methods and data analysis. If granted an <i>in principle acceptance</i>, the manuscript is accepted for publication. Authors complete the manuscript by reporting the results of the registered analyses in Phase Two, but the article is citable (and sometimes even made available online) at the point of acceptance. Registered reports can be especially benficial for graduate students who collect longitudinal data, work with difficult-to-access samples, or who are tackling otherwise ambitious projects that take a lot of time to complete. And again they can help increase the veracity of the science reported by providing a platform for good ideas and well-planned methodology, regardless of the findings. <br><br>Registered reports do require some forethought as most journals won't accept proposals using data that has already been collected (see <a href="https://docs.google.com/spreadsheets/d/1D4_k-8C_UENTRtbPzXfhjEyu3BfLxdOsn9j-otrO870/edit#gid=0" target="null">this list of participating journals</a>). However, even if your project is complete you can post it publicly as a preprint and receive a citable DOI. <b>Preprints</b> are completed manuscripts that have either yet to have been accepted for publication at a journal, or those that have but are in-press. In most cases pre-prints are not the same as the final published article, but they allow the authors to present their work before their peers for feedback. Psychology article preprints can be posted on the <a href="https://psyarxiv.com/" target="null">PsyArXiv</a> (and you can follow <a href="https://twitter.com/PsyArXivBot" target="null">the friendly bot</a> on twitter to be alerted when a new preprint is posted). While posting a preprint by no means that your work is done - the manuscript does need to undergo peer review, after all - it does mean that you have an easy, accesible way to share your project with colleagues while you endure the formal review process.</li><br>
<li><h5>Open science builds your marketable skills.</h5> Psychology grad students are spoiled with potential career options. We can stick to the academic life and profess, run regressions for lots of money in Silicon Valley, use our data wrangling skills for non-profits, or become a superstar science writer with our talents for written and verbal communication. Any field that values teaching, coding, analyzing, and communicating combined with the ability to distinguish truth from fiction is a match for psychologists - and open science initiatives refine these skills. As mentioned before, pre-registration helps grads refine their statistical thinking and get in the habit of moving this process to the forefront of their study design. Opening one's work to a broader audience of peers via registered reports and preprints means more opportunities to improve written communication of complex ideas. And posting data and analysis scripts with the intention of making one's work open and reproducible means constant practice at coding. Since open science is as much of a community as it is a movement in psychology, getting involved also means exposure to peers all over the world who you can learn from. You don't have to rely only on the skills that are taught in your home department or lab, and this will benefit your development as a well-rounded scientist who is competitive for jobs in a variety of fields.</li>     
<li><h5>Open science helps you connect.</h5> There's a truth that I don't hear often spoken aloud but which is nevertheless important for grad students to be aware of: networking matters, even in science. Opportunities for collaborations on projects, speaking in symposia, postdoctoral fellowships, and yes, even full-time careers are to an extent distributed through social networks. Psychology is a pretty big field full of interminably busy people, so it makes sense that we choose to work with people in our immediately accessible environment - people who we know, whose work we've read, and/or who reach out to us to collaborate. The open science movement is therefore beneficial for grad students as it provides many routes to making connections. As previously mentioned, preprints can help get your name and your work out to the community - I've seen many an early career researcher have their preprints praised by some pretty big names on twitter (retweeted often, of course, from the <a href="https://twitter.com/PsyArXivBot" target="null">the helpful bot</a>) which then get picked up across the field. Producing work that is not traditionally rewarded in psychology, such as coding an experimental task or developing an open dataset, can again be assigned a citable DOI through the OSF or other repositories and lead to new collaborations and projects. <a href="http://improvingpsych.org/" target="null">The Society for the Improvement of Psychological Science (SIPS)</a> hosts an annual conference focused on furthering open science which continues to have a max attendance of a couple hundred people, and is therefore a great opportunity for establishing relationships with other scientists. Being open is therefore beneficial not just for the field overall, but also for your professional development and reputation. Engaging with the open science community can be especially beneficial for those who come from staunchly traditional labs or schools, as you'll no doubt find people to learn from and work with.</li></ul>

<blockquote style="text-align:center;background-color:black;color:white;font-family:serif;font-size:150%;"><i>"Any field that values teaching, coding, analyzing, and communicating combined with the ability to distinguish truth from fiction is a match for psychologists - and open science initiatives refine these skills."</i></blockquote>

<p>This is by all means not a comprehensive list of the benefits of open science, but hopefully it is enough to encourage you to try it out if you haven&rsquo;t before. I do believe that while the concerns I&rsquo;ve heard from fellow grads are valid and need to be addressed by the field overall (for example, by reframing the heuristics used to evaluate job candidates), many of them may be due to a lack of experience working within an open framework. Since engaging fully with the movement in my mid-grad school career, I have seen improvements in my statistical reasoning and understanding, my written code, and my productivity. I also feel more confident in the results that I report, even if those results are null, and more comfortable admitting when I just don&rsquo;t have enough evidence to write a tidy conclusion- and I believe these things improve my quality of a scientist as much as the practical skill-building does. The plural of anecdote is not data, but I encourage you to conduct your own research and see if perhaps open science is right for you- because even if the future is unknown, at least the methods you took to predict it will be.</p>

					</div>
				</article>

			</div>
		</div> 

        <div class="row">
			<div class="col-sm-8 col-sm-offset-2">

				<div id="share">
                    
				</div>
			</div>
		</div> 
		<div class="clearfix"></div>

		<div class="row">
			<div class="col-sm-8 col-sm-offset-2">

				<div id="comments">
                    
				</div>
			</div>
		</div> 
		<div class="clearfix"></div>

	</div>	

</main>

<footer id="footer">
	<div class="container">
		<div class="row">
			
			<div class="col-md-3 widget">
				<h3 class="widget-title">Contact</h3>
				<div class="widget-body">
					<p>rludwig[at]uoregon[dot]edu<br>
					</p>
				</div>
			</div>
			

			
			<div class="col-md-3 widget">
				<h3 class="widget-title">Follow me</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                                <a href="https://github.com/rxqx" target="_blank"><i class="fa fa-github fa-2"></i></a>
                            
                        
                            
                        
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p></p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
						Copyright &copy; 2018, Rita M. Ludwig, M.A., M.S.<br>
						Design: <a href="http://www.gettemplate.com" rel="designer">Initio by GetTemplate</a> - 
                        Powered by: <a href="https://gohugo.io/" rel="poweredby">Hugo</a>
                    </p>
				</div>
			</div>

		</div> 
	</div>
</footer>




<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="https://rxqx.github.iojs/template.js"></script>
<script id="dsq-count-scr" src="///count.js" async></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>

</body>
</html>

